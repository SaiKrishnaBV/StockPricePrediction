{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=256):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            self.texts[idx],\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_tensors='pt',\n",
    "            return_attention_mask=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'label': torch.tensor(self.labels[idx])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)  # Adjust num_labels based on your sentiment classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"financial_phrasebank\",'sentences_50agree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = dataset['train']['sentence']\n",
    "labels = dataset['train']['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = SentimentDataset(content, labels, tokenizer)\n",
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macsrini/Desktop/M.Tech/Data_Science_in_Practice/Project/project/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "num_epochs = 3\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Batch 1/303, Loss: 0.8315\n",
      "Epoch 1/3, Batch 2/303, Loss: 0.9681\n",
      "Epoch 1/3, Batch 3/303, Loss: 0.9644\n",
      "Epoch 1/3, Batch 4/303, Loss: 0.9383\n",
      "Epoch 1/3, Batch 5/303, Loss: 0.9501\n",
      "Epoch 1/3, Batch 6/303, Loss: 0.9341\n",
      "Epoch 1/3, Batch 7/303, Loss: 0.9142\n",
      "Epoch 1/3, Batch 8/303, Loss: 0.8991\n",
      "Epoch 1/3, Batch 9/303, Loss: 0.8770\n",
      "Epoch 1/3, Batch 10/303, Loss: 0.8682\n",
      "Epoch 1/3, Batch 11/303, Loss: 0.8640\n",
      "Epoch 1/3, Batch 12/303, Loss: 0.8701\n",
      "Epoch 1/3, Batch 13/303, Loss: 0.8662\n",
      "Epoch 1/3, Batch 14/303, Loss: 0.8452\n",
      "Epoch 1/3, Batch 15/303, Loss: 0.8468\n",
      "Epoch 1/3, Batch 16/303, Loss: 0.8367\n",
      "Epoch 1/3, Batch 17/303, Loss: 0.8442\n",
      "Epoch 1/3, Batch 18/303, Loss: 0.8512\n",
      "Epoch 1/3, Batch 19/303, Loss: 0.8419\n",
      "Epoch 1/3, Batch 20/303, Loss: 0.8497\n",
      "Epoch 1/3, Batch 21/303, Loss: 0.8369\n",
      "Epoch 1/3, Batch 22/303, Loss: 0.8429\n",
      "Epoch 1/3, Batch 23/303, Loss: 0.8417\n",
      "Epoch 1/3, Batch 24/303, Loss: 0.8395\n",
      "Epoch 1/3, Batch 25/303, Loss: 0.8331\n",
      "Epoch 1/3, Batch 26/303, Loss: 0.8267\n",
      "Epoch 1/3, Batch 27/303, Loss: 0.8285\n",
      "Epoch 1/3, Batch 28/303, Loss: 0.8382\n",
      "Epoch 1/3, Batch 29/303, Loss: 0.8236\n",
      "Epoch 1/3, Batch 30/303, Loss: 0.8153\n",
      "Epoch 1/3, Batch 31/303, Loss: 0.8093\n",
      "Epoch 1/3, Batch 32/303, Loss: 0.8074\n",
      "Epoch 1/3, Batch 33/303, Loss: 0.8106\n",
      "Epoch 1/3, Batch 34/303, Loss: 0.8054\n",
      "Epoch 1/3, Batch 35/303, Loss: 0.7965\n",
      "Epoch 1/3, Batch 36/303, Loss: 0.7887\n",
      "Epoch 1/3, Batch 37/303, Loss: 0.7853\n",
      "Epoch 1/3, Batch 38/303, Loss: 0.7848\n",
      "Epoch 1/3, Batch 39/303, Loss: 0.7948\n",
      "Epoch 1/3, Batch 40/303, Loss: 0.7880\n",
      "Epoch 1/3, Batch 41/303, Loss: 0.7830\n",
      "Epoch 1/3, Batch 42/303, Loss: 0.7772\n",
      "Epoch 1/3, Batch 43/303, Loss: 0.7813\n",
      "Epoch 1/3, Batch 44/303, Loss: 0.7777\n",
      "Epoch 1/3, Batch 45/303, Loss: 0.7736\n",
      "Epoch 1/3, Batch 46/303, Loss: 0.7699\n",
      "Epoch 1/3, Batch 47/303, Loss: 0.7630\n",
      "Epoch 1/3, Batch 48/303, Loss: 0.7586\n",
      "Epoch 1/3, Batch 49/303, Loss: 0.7539\n",
      "Epoch 1/3, Batch 50/303, Loss: 0.7500\n",
      "Epoch 1/3, Batch 51/303, Loss: 0.7426\n",
      "Epoch 1/3, Batch 52/303, Loss: 0.7442\n",
      "Epoch 1/3, Batch 53/303, Loss: 0.7374\n",
      "Epoch 1/3, Batch 54/303, Loss: 0.7351\n",
      "Epoch 1/3, Batch 55/303, Loss: 0.7291\n",
      "Epoch 1/3, Batch 56/303, Loss: 0.7241\n",
      "Epoch 1/3, Batch 57/303, Loss: 0.7214\n",
      "Epoch 1/3, Batch 58/303, Loss: 0.7194\n",
      "Epoch 1/3, Batch 59/303, Loss: 0.7159\n",
      "Epoch 1/3, Batch 60/303, Loss: 0.7094\n",
      "Epoch 1/3, Batch 61/303, Loss: 0.7018\n",
      "Epoch 1/3, Batch 62/303, Loss: 0.6963\n",
      "Epoch 1/3, Batch 63/303, Loss: 0.6907\n",
      "Epoch 1/3, Batch 64/303, Loss: 0.6862\n",
      "Epoch 1/3, Batch 65/303, Loss: 0.6859\n",
      "Epoch 1/3, Batch 66/303, Loss: 0.6842\n",
      "Epoch 1/3, Batch 67/303, Loss: 0.6847\n",
      "Epoch 1/3, Batch 68/303, Loss: 0.6824\n",
      "Epoch 1/3, Batch 69/303, Loss: 0.6792\n",
      "Epoch 1/3, Batch 70/303, Loss: 0.6763\n",
      "Epoch 1/3, Batch 71/303, Loss: 0.6736\n",
      "Epoch 1/3, Batch 72/303, Loss: 0.6701\n",
      "Epoch 1/3, Batch 73/303, Loss: 0.6667\n",
      "Epoch 1/3, Batch 74/303, Loss: 0.6632\n",
      "Epoch 1/3, Batch 75/303, Loss: 0.6628\n",
      "Epoch 1/3, Batch 76/303, Loss: 0.6590\n",
      "Epoch 1/3, Batch 77/303, Loss: 0.6573\n",
      "Epoch 1/3, Batch 78/303, Loss: 0.6595\n",
      "Epoch 1/3, Batch 79/303, Loss: 0.6606\n",
      "Epoch 1/3, Batch 80/303, Loss: 0.6610\n",
      "Epoch 1/3, Batch 81/303, Loss: 0.6597\n",
      "Epoch 1/3, Batch 82/303, Loss: 0.6569\n",
      "Epoch 1/3, Batch 83/303, Loss: 0.6520\n",
      "Epoch 1/3, Batch 84/303, Loss: 0.6508\n",
      "Epoch 1/3, Batch 85/303, Loss: 0.6491\n",
      "Epoch 1/3, Batch 86/303, Loss: 0.6517\n",
      "Epoch 1/3, Batch 87/303, Loss: 0.6577\n",
      "Epoch 1/3, Batch 88/303, Loss: 0.6543\n",
      "Epoch 1/3, Batch 89/303, Loss: 0.6526\n",
      "Epoch 1/3, Batch 90/303, Loss: 0.6498\n",
      "Epoch 1/3, Batch 91/303, Loss: 0.6443\n",
      "Epoch 1/3, Batch 92/303, Loss: 0.6404\n",
      "Epoch 1/3, Batch 93/303, Loss: 0.6369\n",
      "Epoch 1/3, Batch 94/303, Loss: 0.6332\n",
      "Epoch 1/3, Batch 95/303, Loss: 0.6367\n",
      "Epoch 1/3, Batch 96/303, Loss: 0.6329\n",
      "Epoch 1/3, Batch 97/303, Loss: 0.6278\n",
      "Epoch 1/3, Batch 98/303, Loss: 0.6250\n",
      "Epoch 1/3, Batch 99/303, Loss: 0.6230\n",
      "Epoch 1/3, Batch 100/303, Loss: 0.6221\n",
      "Epoch 1/3, Batch 101/303, Loss: 0.6194\n",
      "Epoch 1/3, Batch 102/303, Loss: 0.6187\n",
      "Epoch 1/3, Batch 103/303, Loss: 0.6142\n",
      "Epoch 1/3, Batch 104/303, Loss: 0.6121\n",
      "Epoch 1/3, Batch 105/303, Loss: 0.6094\n",
      "Epoch 1/3, Batch 106/303, Loss: 0.6059\n",
      "Epoch 1/3, Batch 107/303, Loss: 0.6053\n",
      "Epoch 1/3, Batch 108/303, Loss: 0.6049\n",
      "Epoch 1/3, Batch 109/303, Loss: 0.6024\n",
      "Epoch 1/3, Batch 110/303, Loss: 0.6026\n",
      "Epoch 1/3, Batch 111/303, Loss: 0.6015\n",
      "Epoch 1/3, Batch 112/303, Loss: 0.6002\n",
      "Epoch 1/3, Batch 113/303, Loss: 0.6023\n",
      "Epoch 1/3, Batch 114/303, Loss: 0.6018\n",
      "Epoch 1/3, Batch 115/303, Loss: 0.5999\n",
      "Epoch 1/3, Batch 116/303, Loss: 0.6000\n",
      "Epoch 1/3, Batch 117/303, Loss: 0.6009\n",
      "Epoch 1/3, Batch 118/303, Loss: 0.5977\n",
      "Epoch 1/3, Batch 119/303, Loss: 0.6006\n",
      "Epoch 1/3, Batch 120/303, Loss: 0.5992\n",
      "Epoch 1/3, Batch 121/303, Loss: 0.6019\n",
      "Epoch 1/3, Batch 122/303, Loss: 0.6011\n",
      "Epoch 1/3, Batch 123/303, Loss: 0.5993\n",
      "Epoch 1/3, Batch 124/303, Loss: 0.5981\n",
      "Epoch 1/3, Batch 125/303, Loss: 0.6011\n",
      "Epoch 1/3, Batch 126/303, Loss: 0.5999\n",
      "Epoch 1/3, Batch 127/303, Loss: 0.6007\n",
      "Epoch 1/3, Batch 128/303, Loss: 0.6002\n",
      "Epoch 1/3, Batch 129/303, Loss: 0.5996\n",
      "Epoch 1/3, Batch 130/303, Loss: 0.5983\n",
      "Epoch 1/3, Batch 131/303, Loss: 0.5973\n",
      "Epoch 1/3, Batch 132/303, Loss: 0.5975\n",
      "Epoch 1/3, Batch 133/303, Loss: 0.5964\n",
      "Epoch 1/3, Batch 134/303, Loss: 0.5958\n",
      "Epoch 1/3, Batch 135/303, Loss: 0.5945\n",
      "Epoch 1/3, Batch 136/303, Loss: 0.5931\n",
      "Epoch 1/3, Batch 137/303, Loss: 0.5922\n",
      "Epoch 1/3, Batch 138/303, Loss: 0.5901\n",
      "Epoch 1/3, Batch 139/303, Loss: 0.5878\n",
      "Epoch 1/3, Batch 140/303, Loss: 0.5882\n",
      "Epoch 1/3, Batch 141/303, Loss: 0.5880\n",
      "Epoch 1/3, Batch 142/303, Loss: 0.5869\n",
      "Epoch 1/3, Batch 143/303, Loss: 0.5847\n",
      "Epoch 1/3, Batch 144/303, Loss: 0.5833\n",
      "Epoch 1/3, Batch 145/303, Loss: 0.5820\n",
      "Epoch 1/3, Batch 146/303, Loss: 0.5825\n",
      "Epoch 1/3, Batch 147/303, Loss: 0.5803\n",
      "Epoch 1/3, Batch 148/303, Loss: 0.5794\n",
      "Epoch 1/3, Batch 149/303, Loss: 0.5782\n",
      "Epoch 1/3, Batch 150/303, Loss: 0.5772\n",
      "Epoch 1/3, Batch 151/303, Loss: 0.5771\n",
      "Epoch 1/3, Batch 152/303, Loss: 0.5752\n",
      "Epoch 1/3, Batch 153/303, Loss: 0.5730\n",
      "Epoch 1/3, Batch 154/303, Loss: 0.5735\n",
      "Epoch 1/3, Batch 155/303, Loss: 0.5744\n",
      "Epoch 1/3, Batch 156/303, Loss: 0.5720\n",
      "Epoch 1/3, Batch 157/303, Loss: 0.5690\n",
      "Epoch 1/3, Batch 158/303, Loss: 0.5669\n",
      "Epoch 1/3, Batch 159/303, Loss: 0.5659\n",
      "Epoch 1/3, Batch 160/303, Loss: 0.5656\n",
      "Epoch 1/3, Batch 161/303, Loss: 0.5648\n",
      "Epoch 1/3, Batch 162/303, Loss: 0.5638\n",
      "Epoch 1/3, Batch 163/303, Loss: 0.5630\n",
      "Epoch 1/3, Batch 164/303, Loss: 0.5628\n",
      "Epoch 1/3, Batch 165/303, Loss: 0.5631\n",
      "Epoch 1/3, Batch 166/303, Loss: 0.5606\n",
      "Epoch 1/3, Batch 167/303, Loss: 0.5597\n",
      "Epoch 1/3, Batch 168/303, Loss: 0.5594\n",
      "Epoch 1/3, Batch 169/303, Loss: 0.5592\n",
      "Epoch 1/3, Batch 170/303, Loss: 0.5579\n",
      "Epoch 1/3, Batch 171/303, Loss: 0.5595\n",
      "Epoch 1/3, Batch 172/303, Loss: 0.5587\n",
      "Epoch 1/3, Batch 173/303, Loss: 0.5589\n",
      "Epoch 1/3, Batch 174/303, Loss: 0.5575\n",
      "Epoch 1/3, Batch 175/303, Loss: 0.5561\n",
      "Epoch 1/3, Batch 176/303, Loss: 0.5544\n",
      "Epoch 1/3, Batch 177/303, Loss: 0.5527\n",
      "Epoch 1/3, Batch 178/303, Loss: 0.5512\n",
      "Epoch 1/3, Batch 179/303, Loss: 0.5504\n",
      "Epoch 1/3, Batch 180/303, Loss: 0.5491\n",
      "Epoch 1/3, Batch 181/303, Loss: 0.5491\n",
      "Epoch 1/3, Batch 182/303, Loss: 0.5485\n",
      "Epoch 1/3, Batch 183/303, Loss: 0.5504\n",
      "Epoch 1/3, Batch 184/303, Loss: 0.5504\n",
      "Epoch 1/3, Batch 185/303, Loss: 0.5500\n",
      "Epoch 1/3, Batch 186/303, Loss: 0.5482\n",
      "Epoch 1/3, Batch 187/303, Loss: 0.5463\n",
      "Epoch 1/3, Batch 188/303, Loss: 0.5451\n",
      "Epoch 1/3, Batch 189/303, Loss: 0.5430\n",
      "Epoch 1/3, Batch 190/303, Loss: 0.5430\n",
      "Epoch 1/3, Batch 191/303, Loss: 0.5423\n",
      "Epoch 1/3, Batch 192/303, Loss: 0.5427\n",
      "Epoch 1/3, Batch 193/303, Loss: 0.5422\n",
      "Epoch 1/3, Batch 194/303, Loss: 0.5402\n",
      "Epoch 1/3, Batch 195/303, Loss: 0.5397\n",
      "Epoch 1/3, Batch 196/303, Loss: 0.5405\n",
      "Epoch 1/3, Batch 197/303, Loss: 0.5395\n",
      "Epoch 1/3, Batch 198/303, Loss: 0.5399\n",
      "Epoch 1/3, Batch 199/303, Loss: 0.5385\n",
      "Epoch 1/3, Batch 200/303, Loss: 0.5362\n",
      "Epoch 1/3, Batch 201/303, Loss: 0.5363\n",
      "Epoch 1/3, Batch 202/303, Loss: 0.5352\n",
      "Epoch 1/3, Batch 203/303, Loss: 0.5345\n",
      "Epoch 1/3, Batch 204/303, Loss: 0.5339\n",
      "Epoch 1/3, Batch 205/303, Loss: 0.5333\n",
      "Epoch 1/3, Batch 206/303, Loss: 0.5330\n",
      "Epoch 1/3, Batch 207/303, Loss: 0.5323\n",
      "Epoch 1/3, Batch 208/303, Loss: 0.5329\n",
      "Epoch 1/3, Batch 209/303, Loss: 0.5322\n",
      "Epoch 1/3, Batch 210/303, Loss: 0.5324\n",
      "Epoch 1/3, Batch 211/303, Loss: 0.5319\n",
      "Epoch 1/3, Batch 212/303, Loss: 0.5311\n",
      "Epoch 1/3, Batch 213/303, Loss: 0.5306\n",
      "Epoch 1/3, Batch 214/303, Loss: 0.5303\n",
      "Epoch 1/3, Batch 215/303, Loss: 0.5305\n",
      "Epoch 1/3, Batch 216/303, Loss: 0.5299\n",
      "Epoch 1/3, Batch 217/303, Loss: 0.5284\n",
      "Epoch 1/3, Batch 218/303, Loss: 0.5273\n",
      "Epoch 1/3, Batch 219/303, Loss: 0.5268\n",
      "Epoch 1/3, Batch 220/303, Loss: 0.5257\n",
      "Epoch 1/3, Batch 221/303, Loss: 0.5260\n",
      "Epoch 1/3, Batch 222/303, Loss: 0.5259\n",
      "Epoch 1/3, Batch 223/303, Loss: 0.5251\n",
      "Epoch 1/3, Batch 224/303, Loss: 0.5248\n",
      "Epoch 1/3, Batch 225/303, Loss: 0.5264\n",
      "Epoch 1/3, Batch 226/303, Loss: 0.5259\n",
      "Epoch 1/3, Batch 227/303, Loss: 0.5245\n",
      "Epoch 1/3, Batch 228/303, Loss: 0.5244\n",
      "Epoch 1/3, Batch 229/303, Loss: 0.5239\n",
      "Epoch 1/3, Batch 230/303, Loss: 0.5227\n",
      "Epoch 1/3, Batch 231/303, Loss: 0.5211\n",
      "Epoch 1/3, Batch 232/303, Loss: 0.5202\n",
      "Epoch 1/3, Batch 233/303, Loss: 0.5203\n",
      "Epoch 1/3, Batch 234/303, Loss: 0.5191\n",
      "Epoch 1/3, Batch 235/303, Loss: 0.5181\n",
      "Epoch 1/3, Batch 236/303, Loss: 0.5172\n",
      "Epoch 1/3, Batch 237/303, Loss: 0.5160\n",
      "Epoch 1/3, Batch 238/303, Loss: 0.5146\n",
      "Epoch 1/3, Batch 239/303, Loss: 0.5142\n",
      "Epoch 1/3, Batch 240/303, Loss: 0.5128\n",
      "Epoch 1/3, Batch 241/303, Loss: 0.5125\n",
      "Epoch 1/3, Batch 242/303, Loss: 0.5133\n",
      "Epoch 1/3, Batch 243/303, Loss: 0.5136\n",
      "Epoch 1/3, Batch 244/303, Loss: 0.5135\n",
      "Epoch 1/3, Batch 245/303, Loss: 0.5132\n",
      "Epoch 1/3, Batch 246/303, Loss: 0.5116\n",
      "Epoch 1/3, Batch 247/303, Loss: 0.5103\n",
      "Epoch 1/3, Batch 248/303, Loss: 0.5100\n",
      "Epoch 1/3, Batch 249/303, Loss: 0.5104\n",
      "Epoch 1/3, Batch 250/303, Loss: 0.5107\n",
      "Epoch 1/3, Batch 251/303, Loss: 0.5106\n",
      "Epoch 1/3, Batch 252/303, Loss: 0.5111\n",
      "Epoch 1/3, Batch 253/303, Loss: 0.5104\n",
      "Epoch 1/3, Batch 254/303, Loss: 0.5107\n",
      "Epoch 1/3, Batch 255/303, Loss: 0.5102\n",
      "Epoch 1/3, Batch 256/303, Loss: 0.5105\n",
      "Epoch 1/3, Batch 257/303, Loss: 0.5130\n",
      "Epoch 1/3, Batch 258/303, Loss: 0.5120\n",
      "Epoch 1/3, Batch 259/303, Loss: 0.5117\n",
      "Epoch 1/3, Batch 260/303, Loss: 0.5104\n",
      "Epoch 1/3, Batch 261/303, Loss: 0.5095\n",
      "Epoch 1/3, Batch 262/303, Loss: 0.5083\n",
      "Epoch 1/3, Batch 263/303, Loss: 0.5076\n",
      "Epoch 1/3, Batch 264/303, Loss: 0.5082\n",
      "Epoch 1/3, Batch 265/303, Loss: 0.5073\n",
      "Epoch 1/3, Batch 266/303, Loss: 0.5070\n",
      "Epoch 1/3, Batch 267/303, Loss: 0.5061\n",
      "Epoch 1/3, Batch 268/303, Loss: 0.5058\n",
      "Epoch 1/3, Batch 269/303, Loss: 0.5048\n",
      "Epoch 1/3, Batch 270/303, Loss: 0.5041\n",
      "Epoch 1/3, Batch 271/303, Loss: 0.5035\n",
      "Epoch 1/3, Batch 272/303, Loss: 0.5035\n",
      "Epoch 1/3, Batch 273/303, Loss: 0.5033\n",
      "Epoch 1/3, Batch 274/303, Loss: 0.5028\n",
      "Epoch 1/3, Batch 275/303, Loss: 0.5023\n",
      "Epoch 1/3, Batch 276/303, Loss: 0.5028\n",
      "Epoch 1/3, Batch 277/303, Loss: 0.5023\n",
      "Epoch 1/3, Batch 278/303, Loss: 0.5016\n",
      "Epoch 1/3, Batch 279/303, Loss: 0.5012\n",
      "Epoch 1/3, Batch 280/303, Loss: 0.5006\n",
      "Epoch 1/3, Batch 281/303, Loss: 0.5000\n",
      "Epoch 1/3, Batch 282/303, Loss: 0.4994\n",
      "Epoch 1/3, Batch 283/303, Loss: 0.4989\n",
      "Epoch 1/3, Batch 284/303, Loss: 0.4988\n",
      "Epoch 1/3, Batch 285/303, Loss: 0.4986\n",
      "Epoch 1/3, Batch 286/303, Loss: 0.4973\n",
      "Epoch 1/3, Batch 287/303, Loss: 0.4961\n",
      "Epoch 1/3, Batch 288/303, Loss: 0.4954\n",
      "Epoch 1/3, Batch 289/303, Loss: 0.4941\n",
      "Epoch 1/3, Batch 290/303, Loss: 0.4934\n",
      "Epoch 1/3, Batch 291/303, Loss: 0.4929\n",
      "Epoch 1/3, Batch 292/303, Loss: 0.4927\n",
      "Epoch 1/3, Batch 293/303, Loss: 0.4914\n",
      "Epoch 1/3, Batch 294/303, Loss: 0.4905\n",
      "Epoch 1/3, Batch 295/303, Loss: 0.4896\n",
      "Epoch 1/3, Batch 296/303, Loss: 0.4886\n",
      "Epoch 1/3, Batch 297/303, Loss: 0.4878\n",
      "Epoch 1/3, Batch 298/303, Loss: 0.4872\n",
      "Epoch 1/3, Batch 299/303, Loss: 0.4870\n",
      "Epoch 1/3, Batch 300/303, Loss: 0.4871\n",
      "Epoch 1/3, Batch 301/303, Loss: 0.4858\n",
      "Epoch 1/3, Batch 302/303, Loss: 0.4861\n",
      "Epoch 1/3, Batch 303/303, Loss: 0.4862\n",
      "Epoch 1/3, Average Training Loss: 0.4862\n",
      "Epoch 2/3, Batch 1/303, Loss: 0.3563\n",
      "Epoch 2/3, Batch 2/303, Loss: 0.3303\n",
      "Epoch 2/3, Batch 3/303, Loss: 0.3771\n",
      "Epoch 2/3, Batch 4/303, Loss: 0.3790\n",
      "Epoch 2/3, Batch 5/303, Loss: 0.4255\n",
      "Epoch 2/3, Batch 6/303, Loss: 0.3782\n",
      "Epoch 2/3, Batch 7/303, Loss: 0.3466\n",
      "Epoch 2/3, Batch 8/303, Loss: 0.3179\n",
      "Epoch 2/3, Batch 9/303, Loss: 0.3214\n",
      "Epoch 2/3, Batch 10/303, Loss: 0.3240\n",
      "Epoch 2/3, Batch 11/303, Loss: 0.3408\n",
      "Epoch 2/3, Batch 12/303, Loss: 0.3482\n",
      "Epoch 2/3, Batch 13/303, Loss: 0.3435\n",
      "Epoch 2/3, Batch 14/303, Loss: 0.3266\n",
      "Epoch 2/3, Batch 15/303, Loss: 0.3547\n",
      "Epoch 2/3, Batch 16/303, Loss: 0.3454\n",
      "Epoch 2/3, Batch 17/303, Loss: 0.3492\n",
      "Epoch 2/3, Batch 18/303, Loss: 0.3367\n",
      "Epoch 2/3, Batch 19/303, Loss: 0.3274\n",
      "Epoch 2/3, Batch 20/303, Loss: 0.3325\n",
      "Epoch 2/3, Batch 21/303, Loss: 0.3287\n",
      "Epoch 2/3, Batch 22/303, Loss: 0.3231\n",
      "Epoch 2/3, Batch 23/303, Loss: 0.3282\n",
      "Epoch 2/3, Batch 24/303, Loss: 0.3227\n",
      "Epoch 2/3, Batch 25/303, Loss: 0.3256\n",
      "Epoch 2/3, Batch 26/303, Loss: 0.3187\n",
      "Epoch 2/3, Batch 27/303, Loss: 0.3106\n",
      "Epoch 2/3, Batch 28/303, Loss: 0.3175\n",
      "Epoch 2/3, Batch 29/303, Loss: 0.3116\n",
      "Epoch 2/3, Batch 30/303, Loss: 0.3068\n",
      "Epoch 2/3, Batch 31/303, Loss: 0.3060\n",
      "Epoch 2/3, Batch 32/303, Loss: 0.3011\n",
      "Epoch 2/3, Batch 33/303, Loss: 0.3002\n",
      "Epoch 2/3, Batch 34/303, Loss: 0.2947\n",
      "Epoch 2/3, Batch 35/303, Loss: 0.2888\n",
      "Epoch 2/3, Batch 36/303, Loss: 0.2825\n",
      "Epoch 2/3, Batch 37/303, Loss: 0.2780\n",
      "Epoch 2/3, Batch 38/303, Loss: 0.2838\n",
      "Epoch 2/3, Batch 39/303, Loss: 0.2832\n",
      "Epoch 2/3, Batch 40/303, Loss: 0.2776\n",
      "Epoch 2/3, Batch 41/303, Loss: 0.2762\n",
      "Epoch 2/3, Batch 42/303, Loss: 0.2851\n",
      "Epoch 2/3, Batch 43/303, Loss: 0.2792\n",
      "Epoch 2/3, Batch 44/303, Loss: 0.2749\n",
      "Epoch 2/3, Batch 45/303, Loss: 0.2697\n",
      "Epoch 2/3, Batch 46/303, Loss: 0.2683\n",
      "Epoch 2/3, Batch 47/303, Loss: 0.2696\n",
      "Epoch 2/3, Batch 48/303, Loss: 0.2673\n",
      "Epoch 2/3, Batch 49/303, Loss: 0.2626\n",
      "Epoch 2/3, Batch 50/303, Loss: 0.2584\n",
      "Epoch 2/3, Batch 51/303, Loss: 0.2544\n",
      "Epoch 2/3, Batch 52/303, Loss: 0.2640\n",
      "Epoch 2/3, Batch 53/303, Loss: 0.2655\n",
      "Epoch 2/3, Batch 54/303, Loss: 0.2632\n",
      "Epoch 2/3, Batch 55/303, Loss: 0.2634\n",
      "Epoch 2/3, Batch 56/303, Loss: 0.2623\n",
      "Epoch 2/3, Batch 57/303, Loss: 0.2663\n",
      "Epoch 2/3, Batch 58/303, Loss: 0.2661\n",
      "Epoch 2/3, Batch 59/303, Loss: 0.2645\n",
      "Epoch 2/3, Batch 60/303, Loss: 0.2688\n",
      "Epoch 2/3, Batch 61/303, Loss: 0.2665\n",
      "Epoch 2/3, Batch 62/303, Loss: 0.2708\n",
      "Epoch 2/3, Batch 63/303, Loss: 0.2684\n",
      "Epoch 2/3, Batch 64/303, Loss: 0.2683\n",
      "Epoch 2/3, Batch 65/303, Loss: 0.2697\n",
      "Epoch 2/3, Batch 66/303, Loss: 0.2701\n",
      "Epoch 2/3, Batch 67/303, Loss: 0.2674\n",
      "Epoch 2/3, Batch 68/303, Loss: 0.2656\n",
      "Epoch 2/3, Batch 69/303, Loss: 0.2623\n",
      "Epoch 2/3, Batch 70/303, Loss: 0.2597\n",
      "Epoch 2/3, Batch 71/303, Loss: 0.2612\n",
      "Epoch 2/3, Batch 72/303, Loss: 0.2600\n",
      "Epoch 2/3, Batch 73/303, Loss: 0.2574\n",
      "Epoch 2/3, Batch 74/303, Loss: 0.2567\n",
      "Epoch 2/3, Batch 75/303, Loss: 0.2550\n",
      "Epoch 2/3, Batch 76/303, Loss: 0.2592\n",
      "Epoch 2/3, Batch 77/303, Loss: 0.2665\n",
      "Epoch 2/3, Batch 78/303, Loss: 0.2720\n",
      "Epoch 2/3, Batch 79/303, Loss: 0.2689\n",
      "Epoch 2/3, Batch 80/303, Loss: 0.2673\n",
      "Epoch 2/3, Batch 81/303, Loss: 0.2678\n",
      "Epoch 2/3, Batch 82/303, Loss: 0.2732\n",
      "Epoch 2/3, Batch 83/303, Loss: 0.2721\n",
      "Epoch 2/3, Batch 84/303, Loss: 0.2760\n",
      "Epoch 2/3, Batch 85/303, Loss: 0.2758\n",
      "Epoch 2/3, Batch 86/303, Loss: 0.2748\n",
      "Epoch 2/3, Batch 87/303, Loss: 0.2766\n",
      "Epoch 2/3, Batch 88/303, Loss: 0.2739\n",
      "Epoch 2/3, Batch 89/303, Loss: 0.2798\n",
      "Epoch 2/3, Batch 90/303, Loss: 0.2816\n",
      "Epoch 2/3, Batch 91/303, Loss: 0.2804\n",
      "Epoch 2/3, Batch 92/303, Loss: 0.2786\n",
      "Epoch 2/3, Batch 93/303, Loss: 0.2765\n",
      "Epoch 2/3, Batch 94/303, Loss: 0.2757\n",
      "Epoch 2/3, Batch 95/303, Loss: 0.2741\n",
      "Epoch 2/3, Batch 96/303, Loss: 0.2733\n",
      "Epoch 2/3, Batch 97/303, Loss: 0.2719\n",
      "Epoch 2/3, Batch 98/303, Loss: 0.2710\n",
      "Epoch 2/3, Batch 99/303, Loss: 0.2715\n",
      "Epoch 2/3, Batch 100/303, Loss: 0.2710\n",
      "Epoch 2/3, Batch 101/303, Loss: 0.2713\n",
      "Epoch 2/3, Batch 102/303, Loss: 0.2715\n",
      "Epoch 2/3, Batch 103/303, Loss: 0.2711\n",
      "Epoch 2/3, Batch 104/303, Loss: 0.2718\n",
      "Epoch 2/3, Batch 105/303, Loss: 0.2703\n",
      "Epoch 2/3, Batch 106/303, Loss: 0.2699\n",
      "Epoch 2/3, Batch 107/303, Loss: 0.2687\n",
      "Epoch 2/3, Batch 108/303, Loss: 0.2679\n",
      "Epoch 2/3, Batch 109/303, Loss: 0.2662\n",
      "Epoch 2/3, Batch 110/303, Loss: 0.2657\n",
      "Epoch 2/3, Batch 111/303, Loss: 0.2643\n",
      "Epoch 2/3, Batch 112/303, Loss: 0.2634\n",
      "Epoch 2/3, Batch 113/303, Loss: 0.2615\n",
      "Epoch 2/3, Batch 114/303, Loss: 0.2607\n",
      "Epoch 2/3, Batch 115/303, Loss: 0.2590\n",
      "Epoch 2/3, Batch 116/303, Loss: 0.2595\n",
      "Epoch 2/3, Batch 117/303, Loss: 0.2619\n",
      "Epoch 2/3, Batch 118/303, Loss: 0.2619\n",
      "Epoch 2/3, Batch 119/303, Loss: 0.2629\n",
      "Epoch 2/3, Batch 120/303, Loss: 0.2615\n",
      "Epoch 2/3, Batch 121/303, Loss: 0.2601\n",
      "Epoch 2/3, Batch 122/303, Loss: 0.2606\n",
      "Epoch 2/3, Batch 123/303, Loss: 0.2604\n",
      "Epoch 2/3, Batch 124/303, Loss: 0.2602\n",
      "Epoch 2/3, Batch 125/303, Loss: 0.2592\n",
      "Epoch 2/3, Batch 126/303, Loss: 0.2615\n",
      "Epoch 2/3, Batch 127/303, Loss: 0.2607\n",
      "Epoch 2/3, Batch 128/303, Loss: 0.2598\n",
      "Epoch 2/3, Batch 129/303, Loss: 0.2596\n",
      "Epoch 2/3, Batch 130/303, Loss: 0.2616\n",
      "Epoch 2/3, Batch 131/303, Loss: 0.2609\n",
      "Epoch 2/3, Batch 132/303, Loss: 0.2617\n",
      "Epoch 2/3, Batch 133/303, Loss: 0.2625\n",
      "Epoch 2/3, Batch 134/303, Loss: 0.2614\n",
      "Epoch 2/3, Batch 135/303, Loss: 0.2614\n",
      "Epoch 2/3, Batch 136/303, Loss: 0.2618\n",
      "Epoch 2/3, Batch 137/303, Loss: 0.2610\n",
      "Epoch 2/3, Batch 138/303, Loss: 0.2606\n",
      "Epoch 2/3, Batch 139/303, Loss: 0.2618\n",
      "Epoch 2/3, Batch 140/303, Loss: 0.2641\n",
      "Epoch 2/3, Batch 141/303, Loss: 0.2642\n",
      "Epoch 2/3, Batch 142/303, Loss: 0.2659\n",
      "Epoch 2/3, Batch 143/303, Loss: 0.2657\n",
      "Epoch 2/3, Batch 144/303, Loss: 0.2656\n",
      "Epoch 2/3, Batch 145/303, Loss: 0.2648\n",
      "Epoch 2/3, Batch 146/303, Loss: 0.2670\n",
      "Epoch 2/3, Batch 147/303, Loss: 0.2681\n",
      "Epoch 2/3, Batch 148/303, Loss: 0.2685\n",
      "Epoch 2/3, Batch 149/303, Loss: 0.2672\n",
      "Epoch 2/3, Batch 150/303, Loss: 0.2658\n",
      "Epoch 2/3, Batch 151/303, Loss: 0.2653\n",
      "Epoch 2/3, Batch 152/303, Loss: 0.2637\n",
      "Epoch 2/3, Batch 153/303, Loss: 0.2625\n",
      "Epoch 2/3, Batch 154/303, Loss: 0.2617\n",
      "Epoch 2/3, Batch 155/303, Loss: 0.2606\n",
      "Epoch 2/3, Batch 156/303, Loss: 0.2592\n",
      "Epoch 2/3, Batch 157/303, Loss: 0.2587\n",
      "Epoch 2/3, Batch 158/303, Loss: 0.2619\n",
      "Epoch 2/3, Batch 159/303, Loss: 0.2642\n",
      "Epoch 2/3, Batch 160/303, Loss: 0.2666\n",
      "Epoch 2/3, Batch 161/303, Loss: 0.2652\n",
      "Epoch 2/3, Batch 162/303, Loss: 0.2659\n",
      "Epoch 2/3, Batch 163/303, Loss: 0.2655\n",
      "Epoch 2/3, Batch 164/303, Loss: 0.2647\n",
      "Epoch 2/3, Batch 165/303, Loss: 0.2649\n",
      "Epoch 2/3, Batch 166/303, Loss: 0.2643\n",
      "Epoch 2/3, Batch 167/303, Loss: 0.2642\n",
      "Epoch 2/3, Batch 168/303, Loss: 0.2634\n",
      "Epoch 2/3, Batch 169/303, Loss: 0.2645\n",
      "Epoch 2/3, Batch 170/303, Loss: 0.2635\n",
      "Epoch 2/3, Batch 171/303, Loss: 0.2627\n",
      "Epoch 2/3, Batch 172/303, Loss: 0.2630\n",
      "Epoch 2/3, Batch 173/303, Loss: 0.2621\n",
      "Epoch 2/3, Batch 174/303, Loss: 0.2611\n",
      "Epoch 2/3, Batch 175/303, Loss: 0.2611\n",
      "Epoch 2/3, Batch 176/303, Loss: 0.2598\n",
      "Epoch 2/3, Batch 177/303, Loss: 0.2591\n",
      "Epoch 2/3, Batch 178/303, Loss: 0.2594\n",
      "Epoch 2/3, Batch 179/303, Loss: 0.2596\n",
      "Epoch 2/3, Batch 180/303, Loss: 0.2603\n",
      "Epoch 2/3, Batch 181/303, Loss: 0.2613\n",
      "Epoch 2/3, Batch 182/303, Loss: 0.2602\n",
      "Epoch 2/3, Batch 183/303, Loss: 0.2600\n",
      "Epoch 2/3, Batch 184/303, Loss: 0.2605\n",
      "Epoch 2/3, Batch 185/303, Loss: 0.2593\n",
      "Epoch 2/3, Batch 186/303, Loss: 0.2587\n",
      "Epoch 2/3, Batch 187/303, Loss: 0.2576\n",
      "Epoch 2/3, Batch 188/303, Loss: 0.2584\n",
      "Epoch 2/3, Batch 189/303, Loss: 0.2584\n",
      "Epoch 2/3, Batch 190/303, Loss: 0.2579\n",
      "Epoch 2/3, Batch 191/303, Loss: 0.2567\n",
      "Epoch 2/3, Batch 192/303, Loss: 0.2562\n",
      "Epoch 2/3, Batch 193/303, Loss: 0.2577\n",
      "Epoch 2/3, Batch 194/303, Loss: 0.2585\n",
      "Epoch 2/3, Batch 195/303, Loss: 0.2593\n",
      "Epoch 2/3, Batch 196/303, Loss: 0.2597\n",
      "Epoch 2/3, Batch 197/303, Loss: 0.2600\n",
      "Epoch 2/3, Batch 198/303, Loss: 0.2596\n",
      "Epoch 2/3, Batch 199/303, Loss: 0.2591\n",
      "Epoch 2/3, Batch 200/303, Loss: 0.2581\n",
      "Epoch 2/3, Batch 201/303, Loss: 0.2582\n",
      "Epoch 2/3, Batch 202/303, Loss: 0.2596\n",
      "Epoch 2/3, Batch 203/303, Loss: 0.2596\n",
      "Epoch 2/3, Batch 204/303, Loss: 0.2602\n",
      "Epoch 2/3, Batch 205/303, Loss: 0.2598\n",
      "Epoch 2/3, Batch 206/303, Loss: 0.2608\n",
      "Epoch 2/3, Batch 207/303, Loss: 0.2601\n",
      "Epoch 2/3, Batch 208/303, Loss: 0.2595\n",
      "Epoch 2/3, Batch 209/303, Loss: 0.2588\n",
      "Epoch 2/3, Batch 210/303, Loss: 0.2585\n",
      "Epoch 2/3, Batch 211/303, Loss: 0.2586\n",
      "Epoch 2/3, Batch 212/303, Loss: 0.2581\n",
      "Epoch 2/3, Batch 213/303, Loss: 0.2590\n",
      "Epoch 2/3, Batch 214/303, Loss: 0.2583\n",
      "Epoch 2/3, Batch 215/303, Loss: 0.2583\n",
      "Epoch 2/3, Batch 216/303, Loss: 0.2581\n",
      "Epoch 2/3, Batch 217/303, Loss: 0.2581\n",
      "Epoch 2/3, Batch 218/303, Loss: 0.2587\n",
      "Epoch 2/3, Batch 219/303, Loss: 0.2582\n",
      "Epoch 2/3, Batch 220/303, Loss: 0.2574\n",
      "Epoch 2/3, Batch 221/303, Loss: 0.2572\n",
      "Epoch 2/3, Batch 222/303, Loss: 0.2569\n",
      "Epoch 2/3, Batch 223/303, Loss: 0.2569\n",
      "Epoch 2/3, Batch 224/303, Loss: 0.2570\n",
      "Epoch 2/3, Batch 225/303, Loss: 0.2563\n",
      "Epoch 2/3, Batch 226/303, Loss: 0.2564\n",
      "Epoch 2/3, Batch 227/303, Loss: 0.2569\n",
      "Epoch 2/3, Batch 228/303, Loss: 0.2562\n",
      "Epoch 2/3, Batch 229/303, Loss: 0.2559\n",
      "Epoch 2/3, Batch 230/303, Loss: 0.2558\n",
      "Epoch 2/3, Batch 231/303, Loss: 0.2561\n",
      "Epoch 2/3, Batch 232/303, Loss: 0.2573\n",
      "Epoch 2/3, Batch 233/303, Loss: 0.2578\n",
      "Epoch 2/3, Batch 234/303, Loss: 0.2596\n",
      "Epoch 2/3, Batch 235/303, Loss: 0.2591\n",
      "Epoch 2/3, Batch 236/303, Loss: 0.2605\n",
      "Epoch 2/3, Batch 237/303, Loss: 0.2605\n",
      "Epoch 2/3, Batch 238/303, Loss: 0.2628\n",
      "Epoch 2/3, Batch 239/303, Loss: 0.2645\n",
      "Epoch 2/3, Batch 240/303, Loss: 0.2672\n",
      "Epoch 2/3, Batch 241/303, Loss: 0.2673\n",
      "Epoch 2/3, Batch 242/303, Loss: 0.2675\n",
      "Epoch 2/3, Batch 243/303, Loss: 0.2686\n",
      "Epoch 2/3, Batch 244/303, Loss: 0.2686\n",
      "Epoch 2/3, Batch 245/303, Loss: 0.2680\n",
      "Epoch 2/3, Batch 246/303, Loss: 0.2684\n",
      "Epoch 2/3, Batch 247/303, Loss: 0.2696\n",
      "Epoch 2/3, Batch 248/303, Loss: 0.2693\n",
      "Epoch 2/3, Batch 249/303, Loss: 0.2689\n",
      "Epoch 2/3, Batch 250/303, Loss: 0.2685\n",
      "Epoch 2/3, Batch 251/303, Loss: 0.2686\n",
      "Epoch 2/3, Batch 252/303, Loss: 0.2681\n",
      "Epoch 2/3, Batch 253/303, Loss: 0.2676\n",
      "Epoch 2/3, Batch 254/303, Loss: 0.2677\n",
      "Epoch 2/3, Batch 255/303, Loss: 0.2671\n",
      "Epoch 2/3, Batch 256/303, Loss: 0.2673\n",
      "Epoch 2/3, Batch 257/303, Loss: 0.2679\n",
      "Epoch 2/3, Batch 258/303, Loss: 0.2681\n",
      "Epoch 2/3, Batch 259/303, Loss: 0.2686\n",
      "Epoch 2/3, Batch 260/303, Loss: 0.2680\n",
      "Epoch 2/3, Batch 261/303, Loss: 0.2689\n",
      "Epoch 2/3, Batch 262/303, Loss: 0.2684\n",
      "Epoch 2/3, Batch 263/303, Loss: 0.2685\n",
      "Epoch 2/3, Batch 264/303, Loss: 0.2680\n",
      "Epoch 2/3, Batch 265/303, Loss: 0.2672\n",
      "Epoch 2/3, Batch 266/303, Loss: 0.2677\n",
      "Epoch 2/3, Batch 267/303, Loss: 0.2672\n",
      "Epoch 2/3, Batch 268/303, Loss: 0.2673\n",
      "Epoch 2/3, Batch 269/303, Loss: 0.2686\n",
      "Epoch 2/3, Batch 270/303, Loss: 0.2695\n",
      "Epoch 2/3, Batch 271/303, Loss: 0.2698\n",
      "Epoch 2/3, Batch 272/303, Loss: 0.2696\n",
      "Epoch 2/3, Batch 273/303, Loss: 0.2694\n",
      "Epoch 2/3, Batch 274/303, Loss: 0.2700\n",
      "Epoch 2/3, Batch 275/303, Loss: 0.2695\n",
      "Epoch 2/3, Batch 276/303, Loss: 0.2692\n",
      "Epoch 2/3, Batch 277/303, Loss: 0.2696\n",
      "Epoch 2/3, Batch 278/303, Loss: 0.2689\n",
      "Epoch 2/3, Batch 279/303, Loss: 0.2686\n",
      "Epoch 2/3, Batch 280/303, Loss: 0.2684\n",
      "Epoch 2/3, Batch 281/303, Loss: 0.2679\n",
      "Epoch 2/3, Batch 282/303, Loss: 0.2677\n",
      "Epoch 2/3, Batch 283/303, Loss: 0.2681\n",
      "Epoch 2/3, Batch 284/303, Loss: 0.2679\n",
      "Epoch 2/3, Batch 285/303, Loss: 0.2684\n",
      "Epoch 2/3, Batch 286/303, Loss: 0.2694\n",
      "Epoch 2/3, Batch 287/303, Loss: 0.2697\n",
      "Epoch 2/3, Batch 288/303, Loss: 0.2696\n",
      "Epoch 2/3, Batch 289/303, Loss: 0.2697\n",
      "Epoch 2/3, Batch 290/303, Loss: 0.2694\n",
      "Epoch 2/3, Batch 291/303, Loss: 0.2702\n",
      "Epoch 2/3, Batch 292/303, Loss: 0.2694\n",
      "Epoch 2/3, Batch 293/303, Loss: 0.2702\n",
      "Epoch 2/3, Batch 294/303, Loss: 0.2698\n",
      "Epoch 2/3, Batch 295/303, Loss: 0.2692\n",
      "Epoch 2/3, Batch 296/303, Loss: 0.2687\n",
      "Epoch 2/3, Batch 297/303, Loss: 0.2696\n",
      "Epoch 2/3, Batch 298/303, Loss: 0.2694\n",
      "Epoch 2/3, Batch 299/303, Loss: 0.2691\n",
      "Epoch 2/3, Batch 300/303, Loss: 0.2692\n",
      "Epoch 2/3, Batch 301/303, Loss: 0.2685\n",
      "Epoch 2/3, Batch 302/303, Loss: 0.2683\n",
      "Epoch 2/3, Batch 303/303, Loss: 0.2684\n",
      "Epoch 2/3, Average Training Loss: 0.2684\n",
      "Epoch 3/3, Batch 1/303, Loss: 0.1802\n",
      "Epoch 3/3, Batch 2/303, Loss: 0.1088\n",
      "Epoch 3/3, Batch 3/303, Loss: 0.1234\n",
      "Epoch 3/3, Batch 4/303, Loss: 0.1163\n",
      "Epoch 3/3, Batch 5/303, Loss: 0.1305\n",
      "Epoch 3/3, Batch 6/303, Loss: 0.1120\n",
      "Epoch 3/3, Batch 7/303, Loss: 0.1206\n",
      "Epoch 3/3, Batch 8/303, Loss: 0.1232\n",
      "Epoch 3/3, Batch 9/303, Loss: 0.1172\n",
      "Epoch 3/3, Batch 10/303, Loss: 0.1308\n",
      "Epoch 3/3, Batch 11/303, Loss: 0.1227\n",
      "Epoch 3/3, Batch 12/303, Loss: 0.1181\n",
      "Epoch 3/3, Batch 13/303, Loss: 0.1320\n",
      "Epoch 3/3, Batch 14/303, Loss: 0.1358\n",
      "Epoch 3/3, Batch 15/303, Loss: 0.1379\n",
      "Epoch 3/3, Batch 16/303, Loss: 0.1483\n",
      "Epoch 3/3, Batch 17/303, Loss: 0.1421\n",
      "Epoch 3/3, Batch 18/303, Loss: 0.1353\n",
      "Epoch 3/3, Batch 19/303, Loss: 0.1392\n",
      "Epoch 3/3, Batch 20/303, Loss: 0.1360\n",
      "Epoch 3/3, Batch 21/303, Loss: 0.1305\n",
      "Epoch 3/3, Batch 22/303, Loss: 0.1433\n",
      "Epoch 3/3, Batch 23/303, Loss: 0.1382\n",
      "Epoch 3/3, Batch 24/303, Loss: 0.1364\n",
      "Epoch 3/3, Batch 25/303, Loss: 0.1350\n",
      "Epoch 3/3, Batch 26/303, Loss: 0.1354\n",
      "Epoch 3/3, Batch 27/303, Loss: 0.1319\n",
      "Epoch 3/3, Batch 28/303, Loss: 0.1319\n",
      "Epoch 3/3, Batch 29/303, Loss: 0.1339\n",
      "Epoch 3/3, Batch 30/303, Loss: 0.1330\n",
      "Epoch 3/3, Batch 31/303, Loss: 0.1314\n",
      "Epoch 3/3, Batch 32/303, Loss: 0.1284\n",
      "Epoch 3/3, Batch 33/303, Loss: 0.1262\n",
      "Epoch 3/3, Batch 34/303, Loss: 0.1235\n",
      "Epoch 3/3, Batch 35/303, Loss: 0.1217\n",
      "Epoch 3/3, Batch 36/303, Loss: 0.1276\n",
      "Epoch 3/3, Batch 37/303, Loss: 0.1278\n",
      "Epoch 3/3, Batch 38/303, Loss: 0.1283\n",
      "Epoch 3/3, Batch 39/303, Loss: 0.1285\n",
      "Epoch 3/3, Batch 40/303, Loss: 0.1375\n",
      "Epoch 3/3, Batch 41/303, Loss: 0.1378\n",
      "Epoch 3/3, Batch 42/303, Loss: 0.1414\n",
      "Epoch 3/3, Batch 43/303, Loss: 0.1414\n",
      "Epoch 3/3, Batch 44/303, Loss: 0.1387\n",
      "Epoch 3/3, Batch 45/303, Loss: 0.1372\n",
      "Epoch 3/3, Batch 46/303, Loss: 0.1371\n",
      "Epoch 3/3, Batch 47/303, Loss: 0.1348\n",
      "Epoch 3/3, Batch 48/303, Loss: 0.1348\n",
      "Epoch 3/3, Batch 49/303, Loss: 0.1327\n",
      "Epoch 3/3, Batch 50/303, Loss: 0.1304\n",
      "Epoch 3/3, Batch 51/303, Loss: 0.1288\n",
      "Epoch 3/3, Batch 52/303, Loss: 0.1268\n",
      "Epoch 3/3, Batch 53/303, Loss: 0.1276\n",
      "Epoch 3/3, Batch 54/303, Loss: 0.1280\n",
      "Epoch 3/3, Batch 55/303, Loss: 0.1259\n",
      "Epoch 3/3, Batch 56/303, Loss: 0.1244\n",
      "Epoch 3/3, Batch 57/303, Loss: 0.1239\n",
      "Epoch 3/3, Batch 58/303, Loss: 0.1221\n",
      "Epoch 3/3, Batch 59/303, Loss: 0.1248\n",
      "Epoch 3/3, Batch 60/303, Loss: 0.1241\n",
      "Epoch 3/3, Batch 61/303, Loss: 0.1225\n",
      "Epoch 3/3, Batch 62/303, Loss: 0.1217\n",
      "Epoch 3/3, Batch 63/303, Loss: 0.1207\n",
      "Epoch 3/3, Batch 64/303, Loss: 0.1194\n",
      "Epoch 3/3, Batch 65/303, Loss: 0.1208\n",
      "Epoch 3/3, Batch 66/303, Loss: 0.1196\n",
      "Epoch 3/3, Batch 67/303, Loss: 0.1186\n",
      "Epoch 3/3, Batch 68/303, Loss: 0.1177\n",
      "Epoch 3/3, Batch 69/303, Loss: 0.1169\n",
      "Epoch 3/3, Batch 70/303, Loss: 0.1226\n",
      "Epoch 3/3, Batch 71/303, Loss: 0.1231\n",
      "Epoch 3/3, Batch 72/303, Loss: 0.1238\n",
      "Epoch 3/3, Batch 73/303, Loss: 0.1256\n",
      "Epoch 3/3, Batch 74/303, Loss: 0.1243\n",
      "Epoch 3/3, Batch 75/303, Loss: 0.1240\n",
      "Epoch 3/3, Batch 76/303, Loss: 0.1230\n",
      "Epoch 3/3, Batch 77/303, Loss: 0.1242\n",
      "Epoch 3/3, Batch 78/303, Loss: 0.1229\n",
      "Epoch 3/3, Batch 79/303, Loss: 0.1227\n",
      "Epoch 3/3, Batch 80/303, Loss: 0.1223\n",
      "Epoch 3/3, Batch 81/303, Loss: 0.1265\n",
      "Epoch 3/3, Batch 82/303, Loss: 0.1254\n",
      "Epoch 3/3, Batch 83/303, Loss: 0.1243\n",
      "Epoch 3/3, Batch 84/303, Loss: 0.1254\n",
      "Epoch 3/3, Batch 85/303, Loss: 0.1241\n",
      "Epoch 3/3, Batch 86/303, Loss: 0.1228\n",
      "Epoch 3/3, Batch 87/303, Loss: 0.1225\n",
      "Epoch 3/3, Batch 88/303, Loss: 0.1230\n",
      "Epoch 3/3, Batch 89/303, Loss: 0.1227\n",
      "Epoch 3/3, Batch 90/303, Loss: 0.1216\n",
      "Epoch 3/3, Batch 91/303, Loss: 0.1203\n",
      "Epoch 3/3, Batch 92/303, Loss: 0.1192\n",
      "Epoch 3/3, Batch 93/303, Loss: 0.1181\n",
      "Epoch 3/3, Batch 94/303, Loss: 0.1171\n",
      "Epoch 3/3, Batch 95/303, Loss: 0.1161\n",
      "Epoch 3/3, Batch 96/303, Loss: 0.1150\n",
      "Epoch 3/3, Batch 97/303, Loss: 0.1152\n",
      "Epoch 3/3, Batch 98/303, Loss: 0.1144\n",
      "Epoch 3/3, Batch 99/303, Loss: 0.1153\n",
      "Epoch 3/3, Batch 100/303, Loss: 0.1152\n",
      "Epoch 3/3, Batch 101/303, Loss: 0.1145\n",
      "Epoch 3/3, Batch 102/303, Loss: 0.1155\n",
      "Epoch 3/3, Batch 103/303, Loss: 0.1145\n",
      "Epoch 3/3, Batch 104/303, Loss: 0.1142\n",
      "Epoch 3/3, Batch 105/303, Loss: 0.1135\n",
      "Epoch 3/3, Batch 106/303, Loss: 0.1148\n",
      "Epoch 3/3, Batch 107/303, Loss: 0.1140\n",
      "Epoch 3/3, Batch 108/303, Loss: 0.1134\n",
      "Epoch 3/3, Batch 109/303, Loss: 0.1126\n",
      "Epoch 3/3, Batch 110/303, Loss: 0.1121\n",
      "Epoch 3/3, Batch 111/303, Loss: 0.1112\n",
      "Epoch 3/3, Batch 112/303, Loss: 0.1104\n",
      "Epoch 3/3, Batch 113/303, Loss: 0.1095\n",
      "Epoch 3/3, Batch 114/303, Loss: 0.1087\n",
      "Epoch 3/3, Batch 115/303, Loss: 0.1078\n",
      "Epoch 3/3, Batch 116/303, Loss: 0.1074\n",
      "Epoch 3/3, Batch 117/303, Loss: 0.1074\n",
      "Epoch 3/3, Batch 118/303, Loss: 0.1075\n",
      "Epoch 3/3, Batch 119/303, Loss: 0.1069\n",
      "Epoch 3/3, Batch 120/303, Loss: 0.1060\n",
      "Epoch 3/3, Batch 121/303, Loss: 0.1092\n",
      "Epoch 3/3, Batch 122/303, Loss: 0.1089\n",
      "Epoch 3/3, Batch 123/303, Loss: 0.1099\n",
      "Epoch 3/3, Batch 124/303, Loss: 0.1091\n",
      "Epoch 3/3, Batch 125/303, Loss: 0.1085\n",
      "Epoch 3/3, Batch 126/303, Loss: 0.1089\n",
      "Epoch 3/3, Batch 127/303, Loss: 0.1084\n",
      "Epoch 3/3, Batch 128/303, Loss: 0.1115\n",
      "Epoch 3/3, Batch 129/303, Loss: 0.1109\n",
      "Epoch 3/3, Batch 130/303, Loss: 0.1101\n",
      "Epoch 3/3, Batch 131/303, Loss: 0.1119\n",
      "Epoch 3/3, Batch 132/303, Loss: 0.1111\n",
      "Epoch 3/3, Batch 133/303, Loss: 0.1104\n",
      "Epoch 3/3, Batch 134/303, Loss: 0.1100\n",
      "Epoch 3/3, Batch 135/303, Loss: 0.1122\n",
      "Epoch 3/3, Batch 136/303, Loss: 0.1178\n",
      "Epoch 3/3, Batch 137/303, Loss: 0.1176\n",
      "Epoch 3/3, Batch 138/303, Loss: 0.1169\n",
      "Epoch 3/3, Batch 139/303, Loss: 0.1184\n",
      "Epoch 3/3, Batch 140/303, Loss: 0.1186\n",
      "Epoch 3/3, Batch 141/303, Loss: 0.1185\n",
      "Epoch 3/3, Batch 142/303, Loss: 0.1178\n",
      "Epoch 3/3, Batch 143/303, Loss: 0.1176\n",
      "Epoch 3/3, Batch 144/303, Loss: 0.1183\n",
      "Epoch 3/3, Batch 145/303, Loss: 0.1185\n",
      "Epoch 3/3, Batch 146/303, Loss: 0.1224\n",
      "Epoch 3/3, Batch 147/303, Loss: 0.1228\n",
      "Epoch 3/3, Batch 148/303, Loss: 0.1230\n",
      "Epoch 3/3, Batch 149/303, Loss: 0.1224\n",
      "Epoch 3/3, Batch 150/303, Loss: 0.1229\n",
      "Epoch 3/3, Batch 151/303, Loss: 0.1223\n",
      "Epoch 3/3, Batch 152/303, Loss: 0.1221\n",
      "Epoch 3/3, Batch 153/303, Loss: 0.1221\n",
      "Epoch 3/3, Batch 154/303, Loss: 0.1217\n",
      "Epoch 3/3, Batch 155/303, Loss: 0.1210\n",
      "Epoch 3/3, Batch 156/303, Loss: 0.1217\n",
      "Epoch 3/3, Batch 157/303, Loss: 0.1214\n",
      "Epoch 3/3, Batch 158/303, Loss: 0.1217\n",
      "Epoch 3/3, Batch 159/303, Loss: 0.1217\n",
      "Epoch 3/3, Batch 160/303, Loss: 0.1224\n",
      "Epoch 3/3, Batch 161/303, Loss: 0.1219\n",
      "Epoch 3/3, Batch 162/303, Loss: 0.1220\n",
      "Epoch 3/3, Batch 163/303, Loss: 0.1222\n",
      "Epoch 3/3, Batch 164/303, Loss: 0.1220\n",
      "Epoch 3/3, Batch 165/303, Loss: 0.1226\n",
      "Epoch 3/3, Batch 166/303, Loss: 0.1225\n",
      "Epoch 3/3, Batch 167/303, Loss: 0.1232\n",
      "Epoch 3/3, Batch 168/303, Loss: 0.1226\n",
      "Epoch 3/3, Batch 169/303, Loss: 0.1230\n",
      "Epoch 3/3, Batch 170/303, Loss: 0.1225\n",
      "Epoch 3/3, Batch 171/303, Loss: 0.1230\n",
      "Epoch 3/3, Batch 172/303, Loss: 0.1225\n",
      "Epoch 3/3, Batch 173/303, Loss: 0.1220\n",
      "Epoch 3/3, Batch 174/303, Loss: 0.1219\n",
      "Epoch 3/3, Batch 175/303, Loss: 0.1214\n",
      "Epoch 3/3, Batch 176/303, Loss: 0.1208\n",
      "Epoch 3/3, Batch 177/303, Loss: 0.1234\n",
      "Epoch 3/3, Batch 178/303, Loss: 0.1228\n",
      "Epoch 3/3, Batch 179/303, Loss: 0.1235\n",
      "Epoch 3/3, Batch 180/303, Loss: 0.1229\n",
      "Epoch 3/3, Batch 181/303, Loss: 0.1224\n",
      "Epoch 3/3, Batch 182/303, Loss: 0.1228\n",
      "Epoch 3/3, Batch 183/303, Loss: 0.1233\n",
      "Epoch 3/3, Batch 184/303, Loss: 0.1242\n",
      "Epoch 3/3, Batch 185/303, Loss: 0.1244\n",
      "Epoch 3/3, Batch 186/303, Loss: 0.1251\n",
      "Epoch 3/3, Batch 187/303, Loss: 0.1250\n",
      "Epoch 3/3, Batch 188/303, Loss: 0.1245\n",
      "Epoch 3/3, Batch 189/303, Loss: 0.1258\n",
      "Epoch 3/3, Batch 190/303, Loss: 0.1255\n",
      "Epoch 3/3, Batch 191/303, Loss: 0.1249\n",
      "Epoch 3/3, Batch 192/303, Loss: 0.1244\n",
      "Epoch 3/3, Batch 193/303, Loss: 0.1243\n",
      "Epoch 3/3, Batch 194/303, Loss: 0.1244\n",
      "Epoch 3/3, Batch 195/303, Loss: 0.1239\n",
      "Epoch 3/3, Batch 196/303, Loss: 0.1235\n",
      "Epoch 3/3, Batch 197/303, Loss: 0.1251\n",
      "Epoch 3/3, Batch 198/303, Loss: 0.1258\n",
      "Epoch 3/3, Batch 199/303, Loss: 0.1255\n",
      "Epoch 3/3, Batch 200/303, Loss: 0.1263\n",
      "Epoch 3/3, Batch 201/303, Loss: 0.1278\n",
      "Epoch 3/3, Batch 202/303, Loss: 0.1272\n",
      "Epoch 3/3, Batch 203/303, Loss: 0.1276\n",
      "Epoch 3/3, Batch 204/303, Loss: 0.1277\n",
      "Epoch 3/3, Batch 205/303, Loss: 0.1273\n",
      "Epoch 3/3, Batch 206/303, Loss: 0.1272\n",
      "Epoch 3/3, Batch 207/303, Loss: 0.1274\n",
      "Epoch 3/3, Batch 208/303, Loss: 0.1271\n",
      "Epoch 3/3, Batch 209/303, Loss: 0.1270\n",
      "Epoch 3/3, Batch 210/303, Loss: 0.1275\n",
      "Epoch 3/3, Batch 211/303, Loss: 0.1285\n",
      "Epoch 3/3, Batch 212/303, Loss: 0.1286\n",
      "Epoch 3/3, Batch 213/303, Loss: 0.1287\n",
      "Epoch 3/3, Batch 214/303, Loss: 0.1288\n",
      "Epoch 3/3, Batch 215/303, Loss: 0.1286\n",
      "Epoch 3/3, Batch 216/303, Loss: 0.1292\n",
      "Epoch 3/3, Batch 217/303, Loss: 0.1294\n",
      "Epoch 3/3, Batch 218/303, Loss: 0.1294\n",
      "Epoch 3/3, Batch 219/303, Loss: 0.1290\n",
      "Epoch 3/3, Batch 220/303, Loss: 0.1304\n",
      "Epoch 3/3, Batch 221/303, Loss: 0.1302\n",
      "Epoch 3/3, Batch 222/303, Loss: 0.1307\n",
      "Epoch 3/3, Batch 223/303, Loss: 0.1314\n",
      "Epoch 3/3, Batch 224/303, Loss: 0.1313\n",
      "Epoch 3/3, Batch 225/303, Loss: 0.1320\n",
      "Epoch 3/3, Batch 226/303, Loss: 0.1318\n",
      "Epoch 3/3, Batch 227/303, Loss: 0.1320\n",
      "Epoch 3/3, Batch 228/303, Loss: 0.1318\n",
      "Epoch 3/3, Batch 229/303, Loss: 0.1326\n",
      "Epoch 3/3, Batch 230/303, Loss: 0.1326\n",
      "Epoch 3/3, Batch 231/303, Loss: 0.1326\n",
      "Epoch 3/3, Batch 232/303, Loss: 0.1325\n",
      "Epoch 3/3, Batch 233/303, Loss: 0.1332\n",
      "Epoch 3/3, Batch 234/303, Loss: 0.1327\n",
      "Epoch 3/3, Batch 235/303, Loss: 0.1323\n",
      "Epoch 3/3, Batch 236/303, Loss: 0.1324\n",
      "Epoch 3/3, Batch 237/303, Loss: 0.1327\n",
      "Epoch 3/3, Batch 238/303, Loss: 0.1324\n",
      "Epoch 3/3, Batch 239/303, Loss: 0.1334\n",
      "Epoch 3/3, Batch 240/303, Loss: 0.1354\n",
      "Epoch 3/3, Batch 241/303, Loss: 0.1362\n",
      "Epoch 3/3, Batch 242/303, Loss: 0.1368\n",
      "Epoch 3/3, Batch 243/303, Loss: 0.1365\n",
      "Epoch 3/3, Batch 244/303, Loss: 0.1391\n",
      "Epoch 3/3, Batch 245/303, Loss: 0.1386\n",
      "Epoch 3/3, Batch 246/303, Loss: 0.1386\n",
      "Epoch 3/3, Batch 247/303, Loss: 0.1382\n",
      "Epoch 3/3, Batch 248/303, Loss: 0.1377\n",
      "Epoch 3/3, Batch 249/303, Loss: 0.1373\n",
      "Epoch 3/3, Batch 250/303, Loss: 0.1370\n",
      "Epoch 3/3, Batch 251/303, Loss: 0.1379\n",
      "Epoch 3/3, Batch 252/303, Loss: 0.1375\n",
      "Epoch 3/3, Batch 253/303, Loss: 0.1371\n",
      "Epoch 3/3, Batch 254/303, Loss: 0.1380\n",
      "Epoch 3/3, Batch 255/303, Loss: 0.1383\n",
      "Epoch 3/3, Batch 256/303, Loss: 0.1381\n",
      "Epoch 3/3, Batch 257/303, Loss: 0.1379\n",
      "Epoch 3/3, Batch 258/303, Loss: 0.1375\n",
      "Epoch 3/3, Batch 259/303, Loss: 0.1372\n",
      "Epoch 3/3, Batch 260/303, Loss: 0.1387\n",
      "Epoch 3/3, Batch 261/303, Loss: 0.1383\n",
      "Epoch 3/3, Batch 262/303, Loss: 0.1390\n",
      "Epoch 3/3, Batch 263/303, Loss: 0.1390\n",
      "Epoch 3/3, Batch 264/303, Loss: 0.1386\n",
      "Epoch 3/3, Batch 265/303, Loss: 0.1390\n",
      "Epoch 3/3, Batch 266/303, Loss: 0.1387\n",
      "Epoch 3/3, Batch 267/303, Loss: 0.1384\n",
      "Epoch 3/3, Batch 268/303, Loss: 0.1382\n",
      "Epoch 3/3, Batch 269/303, Loss: 0.1380\n",
      "Epoch 3/3, Batch 270/303, Loss: 0.1384\n",
      "Epoch 3/3, Batch 271/303, Loss: 0.1386\n",
      "Epoch 3/3, Batch 272/303, Loss: 0.1390\n",
      "Epoch 3/3, Batch 273/303, Loss: 0.1387\n",
      "Epoch 3/3, Batch 274/303, Loss: 0.1388\n",
      "Epoch 3/3, Batch 275/303, Loss: 0.1387\n",
      "Epoch 3/3, Batch 276/303, Loss: 0.1386\n",
      "Epoch 3/3, Batch 277/303, Loss: 0.1384\n",
      "Epoch 3/3, Batch 278/303, Loss: 0.1385\n",
      "Epoch 3/3, Batch 279/303, Loss: 0.1382\n",
      "Epoch 3/3, Batch 280/303, Loss: 0.1387\n",
      "Epoch 3/3, Batch 281/303, Loss: 0.1389\n",
      "Epoch 3/3, Batch 282/303, Loss: 0.1390\n",
      "Epoch 3/3, Batch 283/303, Loss: 0.1390\n",
      "Epoch 3/3, Batch 284/303, Loss: 0.1393\n",
      "Epoch 3/3, Batch 285/303, Loss: 0.1394\n",
      "Epoch 3/3, Batch 286/303, Loss: 0.1391\n",
      "Epoch 3/3, Batch 287/303, Loss: 0.1394\n",
      "Epoch 3/3, Batch 288/303, Loss: 0.1392\n",
      "Epoch 3/3, Batch 289/303, Loss: 0.1398\n",
      "Epoch 3/3, Batch 290/303, Loss: 0.1395\n",
      "Epoch 3/3, Batch 291/303, Loss: 0.1391\n",
      "Epoch 3/3, Batch 292/303, Loss: 0.1387\n",
      "Epoch 3/3, Batch 293/303, Loss: 0.1394\n",
      "Epoch 3/3, Batch 294/303, Loss: 0.1393\n",
      "Epoch 3/3, Batch 295/303, Loss: 0.1389\n",
      "Epoch 3/3, Batch 296/303, Loss: 0.1386\n",
      "Epoch 3/3, Batch 297/303, Loss: 0.1382\n",
      "Epoch 3/3, Batch 298/303, Loss: 0.1378\n",
      "Epoch 3/3, Batch 299/303, Loss: 0.1381\n",
      "Epoch 3/3, Batch 300/303, Loss: 0.1380\n",
      "Epoch 3/3, Batch 301/303, Loss: 0.1376\n",
      "Epoch 3/3, Batch 302/303, Loss: 0.1374\n",
      "Epoch 3/3, Batch 303/303, Loss: 0.1370\n",
      "Epoch 3/3, Average Training Loss: 0.1370\n"
     ]
    }
   ],
   "source": [
    "print_interval = 1\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx,batch in enumerate(train_loader):\n",
    "        input_ids, attention_mask, labels = batch['input_ids'], batch['attention_mask'], batch['label']\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % print_interval == 0:\n",
    "            average_loss = total_loss / (batch_idx + 1)\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs}, Batch {batch_idx + 1}/{len(train_loader)}, Loss: {average_loss:.4f}')\n",
    "\n",
    "    average_loss_epoch = total_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Average Training Loss: {average_loss_epoch:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"fine_tuned_sentiment_model.pt\"\n",
    "torch.save(model,filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
